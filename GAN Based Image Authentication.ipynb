{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d459919a",
   "metadata": {},
   "source": [
    "# Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b166b76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c341618",
   "metadata": {},
   "source": [
    "# Loading and Preprocessing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28344fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def load_images(image_folder, image_size=(64, 64)):\n",
    "    images = []\n",
    "    for filename in os.listdir(image_folder):\n",
    "        img_path = os.path.join(image_folder, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        \n",
    "        if img is not None:   \n",
    "            img = cv2.resize(img, image_size)  # Resize to a standard size\n",
    "            img = (img / 127.5) - 1  # Normalize to [-1, 1]\n",
    "            images.append(img.astype(np.float32))\n",
    "        \n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "real_images = load_images(\"C:\\\\Users\\\\Deepak kumar\\\\GAN_Project\\\\Dataset\\\\casia_v2\\\\Au_jpg\")\n",
    "fake_images = load_images(\"C:\\\\Users\\\\Deepak kumar\\\\GAN_Project\\\\Dataset\\\\casia_v2\\\\Tp_jpg\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db5a6595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training real images: 5949, Training fake images: 4098\n"
     ]
    }
   ],
   "source": [
    "train_real = real_images[:int(0.8 * len(real_images))]\n",
    "train_fake = fake_images[:int(0.8 * len(fake_images))]\n",
    "test_real = real_images[int(0.8 * len(real_images)):]\n",
    "test_fake = fake_images[int(0.8 * len(fake_images)):]\n",
    "\n",
    "print(f\"Training real images: {len(train_real)}, Training fake images: {len(train_fake)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f5f4dd",
   "metadata": {},
   "source": [
    "# CycleGAN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00d30cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, BatchNormalization, ReLU, LeakyReLU\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def build_generator(input_shape=(64, 64, 3)):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Encoder: Downsampling\n",
    "    x = Conv2D(64, kernel_size=4, strides=2, padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    x = Conv2D(128, kernel_size=4, strides=2, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    # Bottleneck\n",
    "    x = Conv2D(256, kernel_size=4, strides=2, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    # Decoder: Upsampling\n",
    "    x = Conv2DTranspose(128, kernel_size=4, strides=2, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    x = Conv2DTranspose(64, kernel_size=4, strides=2, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    output = Conv2DTranspose(3, kernel_size=4, strides=2, padding='same', activation='tanh')(x)\n",
    "    \n",
    "    model = Model(inputs, output)\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6c0c49",
   "metadata": {},
   "source": [
    "# Discriminator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8c24a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(input_shape=(64, 64, 3)):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    x = Conv2D(64, kernel_size=4, strides=2, padding='same')(inputs)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    \n",
    "    x = Conv2D(128, kernel_size=4, strides=2, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    \n",
    "    x = Conv2D(256, kernel_size=4, strides=2, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    \n",
    "    output = Conv2D(1, kernel_size=4, strides=1, padding='same')(x)  # Output a single value (real/fake)\n",
    "    \n",
    "    model = Model(inputs, output)\n",
    "    return model\n",
    "\n",
    "generator_A_to_B = build_generator()\n",
    "generator_B_to_A = build_generator()\n",
    "discriminator_A = build_discriminator()  # Real images (au)\n",
    "discriminator_B = build_discriminator()  # Fake images (tp)\n",
    "\n",
    "optimizer_G_A_to_B = tf.keras.optimizers.Adam(learning_rate=1e-4, beta_1=0.5)\n",
    "optimizer_G_B_to_A = tf.keras.optimizers.Adam(learning_rate=1e-4, beta_1=0.5)\n",
    "optimizer_D_A = tf.keras.optimizers.Adam(learning_rate=1e-4, beta_1=0.5)\n",
    "optimizer_D_B = tf.keras.optimizers.Adam(learning_rate=1e-4, beta_1=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a536d2",
   "metadata": {},
   "source": [
    "# Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26e4e744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_loss(y_true, y_pred):\n",
    "    return tf.keras.losses.BinaryCrossentropy(from_logits=True)(y_true, y_pred)\n",
    "\n",
    "def cycle_loss(real_image, cycled_image):\n",
    "    return tf.reduce_mean(tf.abs(real_image - cycled_image))\n",
    "\n",
    "def identity_loss(real_image, same_image):\n",
    "    return tf.reduce_mean(tf.abs(real_image - same_image))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74eb61c1",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dcf0176",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(real_A, real_B):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        # Generate fake images\n",
    "        fake_B = generator_A_to_B(real_A)\n",
    "        fake_A = generator_B_to_A(real_B)\n",
    "\n",
    "        # Reconstruct images (cycle consistency)\n",
    "        cycled_A = generator_B_to_A(fake_B)\n",
    "        cycled_B = generator_A_to_B(fake_A)\n",
    "\n",
    "        # Identity loss\n",
    "        same_A = generator_B_to_A(real_A)  # Should be equal to real_A\n",
    "        same_B = generator_A_to_B(real_B)  # Should be equal to real_B\n",
    "\n",
    "        # Discriminator outputs\n",
    "        disc_real_A = discriminator_A(real_A)\n",
    "        disc_fake_A = discriminator_A(fake_A)\n",
    "\n",
    "        disc_real_B = discriminator_B(real_B)\n",
    "        disc_fake_B = discriminator_B(fake_B)\n",
    "\n",
    "        # Generator losses\n",
    "        gen_A_to_B_loss = adversarial_loss(tf.ones_like(disc_fake_B), disc_fake_B) + cycle_loss(real_A, cycled_A) + identity_loss(real_A,same_A) \n",
    "        gen_B_to_A_loss = adversarial_loss(tf.ones_like(disc_fake_A), disc_fake_A) + cycle_loss(real_B , cycled_B) + identity_loss(real_B,same_B)\n",
    "\n",
    "        # Discriminator losses\n",
    "        disc_A_loss = adversarial_loss(tf.ones_like(disc_real_A), disc_real_A) + adversarial_loss(tf.zeros_like(disc_fake_A), disc_fake_A) \n",
    "        disc_B_loss = adversarial_loss(tf.ones_like(disc_real_B), disc_real_B) + adversarial_loss(tf.zeros_like(disc_fake_B), disc_fake_B)\n",
    "\n",
    "    # Compute gradients for the generators and discriminators\n",
    "    grads_G_A_to_B = tape.gradient(gen_A_to_B_loss , generator_A_to_B.trainable_variables )\n",
    "    grads_G_B_to_A=tape.gradient(gen_B_to_A_loss , generator_B_to_A.trainable_variables )\n",
    "    \n",
    "    grads_D_A=tape.gradient(disc_A_loss , discriminator_A.trainable_variables )\n",
    "    grads_D_B=tape.gradient(disc_B_loss , discriminator_B.trainable_variables )\n",
    "\n",
    "    # Apply gradients to optimizers\n",
    "    optimizer_G_A_to_B.apply_gradients(zip(grads_G_A_to_B , generator_A_to_B.trainable_variables ))\n",
    "    optimizer_G_B_to_A.apply_gradients(zip(grads_G_B_to_A , generator_B_to_A.trainable_variables ))\n",
    "    \n",
    "    optimizer_D_A.apply_gradients(zip(grads_D_A , discriminator_A.trainable_variables ))\n",
    "    optimizer_D_B.apply_gradients(zip(grads_D_B , discriminator_B.trainable_variables ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3864084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "\n",
    "# Convert to TensorFlow datasets\n",
    "train_real_dataset = tf.data.Dataset.from_tensor_slices(train_real)\n",
    "train_fake_dataset = tf.data.Dataset.from_tensor_slices(train_fake)\n",
    "\n",
    "# Shuffle and batch the datasets\n",
    "train_real_dataset = train_real_dataset.shuffle(len(train_real)).batch(batch_size)\n",
    "train_fake_dataset = train_fake_dataset.shuffle(len(train_fake)).batch(batch_size)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for real_a , real_b in zip(train_real_dataset , train_fake_dataset):\n",
    "        train_step(real_a , real_b )\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} completed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49fa692",
   "metadata": {},
   "source": [
    "# Classifying Real vs Fake Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6bdf3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(image, discriminator):\n",
    "    prediction = discriminator(image).numpy().mean()\n",
    "    return \"Real\" if prediction >= 0.5 else \"Fake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee992815",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Lists to store true labels and predictions\n",
    "true_labels = []\n",
    "predictions = []\n",
    "\n",
    "# Classify real images in the test set\n",
    "for img in test_real:\n",
    "    img_resized = cv2.resize(img, (64, 64))\n",
    "    img_normalized = (img_resized / 127.5) - 1\n",
    "    pred = classify_image(img_normalized[np.newaxis, ...], discriminator_A)\n",
    "    predictions.append(1 if pred == \"Real\" else 0)\n",
    "    true_labels.append(1)  # True label for real images is 1\n",
    "\n",
    "# Classify fake images in the test set\n",
    "for img in test_fake:\n",
    "    img_resized = cv2.resize(img, (64, 64))\n",
    "    img_normalized = (img_resized / 127.5) - 1\n",
    "    pred = classify_image(img_normalized[np.newaxis, ...], discriminator_A)\n",
    "    predictions.append(1 if pred == \"Real\" else 0)\n",
    "    true_labels.append(0)  # True label for fake images is 0\n",
    "\n",
    "# Step 2: Calculate Performance Metrics\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "precision = precision_score(true_labels, predictions)\n",
    "recall = recall_score(true_labels, predictions)\n",
    "f1 = f1_score(true_labels, predictions)\n",
    "\n",
    "print(f\"Discriminator Performance on Test Set:\")\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "print(f\"F1 Score: {f1 * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dc2ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the generator and discriminator models\n",
    "generator_A_to_B.save(\"C:\\\\Users\\\\Deepak kumar\\\\GAN_Project\\\\Trained_model\\\\discriminator_A.h5\")\n",
    "generator_B_to_A.save(\"C:\\\\Users\\\\Deepak kumar\\\\GAN_Project\\\\Trained_model\\\\generator_B_to_A.h5\")\n",
    "discriminator_A.save(\"C:\\\\Users\\\\Deepak kumar\\\\GAN_Project\\\\Trained_model\\\\discriminator_A.h5\")\n",
    "discriminator_B.save(\"C:\\\\Users\\\\Deepak kumar\\\\GAN_Project\\\\Trained_model\\\\discriminator_B.h5\")\n",
    "\n",
    "print(\"Models saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
